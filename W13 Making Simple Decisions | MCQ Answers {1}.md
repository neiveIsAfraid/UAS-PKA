**Question 1**
What is the core principle that defines a rational decision-theoretic agent's action selection in uncertain environments?
**C) Maximizing the expected utility (MEU) of the action outcomes.**
*Supporting Quote: "The expected utility of an action given the evidence, EU(a), is just the Expected utility the agent expects to derive, on average, given the probabilities and utilities of each outcome."; "The basic principle of decision theory: the maximization of expected utility.".*

**Question 2**
In decision theory, what is the term used to describe the set of uncertain possible outcomes resulting from an action?
**B) Lottery**
*Supporting Quote: "We can think of the set of outcomes for each action as a **lottery**—think of each action as a ticket.".*

**Question 3**
Which constraint (axiom of utility theory) dictates that if an agent prefers A to B and B to C, it must also prefer A to C?
**D) Transitivity**
*Supporting Quote: (Referring to preferences) "Transitivity. If A $ \succ$ B and B $ \succ$ C, then A $ \succ$ C (i.e., if you prefer A to B and prefer B to C, you must prefer A to C).".*

**Question 4**
What type of node is used in a Decision Network (Influence Diagram) to explicitly represent the agent's choice of action?
**B) Decision node (rectangle)**
*Supporting Quote: "Decision nodes (rectangles) represent points where the decision maker has a choice of actions.".*

**Question 5**
What is the definition of **Stochastic Dominance** in the context of multiattribute utility theory?
**B) A preference relation where one uncertain option is demonstrably better than another regardless of the specific utility function, based on their cumulative probability distributions.**
*Supporting Quote: "Fortunately, there is a more useful generalization called **stochastic dominance**, which Stochastic dominance occurs very frequently in real problems."; Stochastic dominance is a preference relation where one uncertain option is demonstrably better than another, regardless of the specific utility function, based on their cumulative probability distributions.".*

**Question 6**
What is the primary purpose of the **Utility Function U(s)** in decision theory?
**C) To assign a single numerical value representing the desirability of a state.**
*Supporting Quote: "The agent’s preferences are captured by a **utility function**, U(s), which assigns a single number to express the desirability of a state.".*

**Question 7**
Which property holds true for the **Expected Value of Information (VPI)**, according to a theorem derived from its definition?
**C) VPI is always non-negative.**
*Supporting Quote: "The expected value of information is nonnegative: $ \forall j VPI(E j)\ge 0$.".*

**Question 8**
The term **"predictably irrational"** is often used in descriptive theories of human judgment. What contrast does this term highlight?
**A) The contrast between observed human behavior and the expected behavior described by normative theory.**
*Supporting Quote: "Decision theory is a **normative theory**: it describes how a rational agent should act. A **descriptive theory**, on the other hand, describes how actual agents—for example, humans—really do act. The evidence suggests that humans are 'predictably irrational'.".*

**Question 9**
When evaluating a Decision Network, what type of node behaves exactly like a chance node that has been set as an evidence variable after the agent commits to an action?
**C) Decision node**
*Supporting Quote: "Once the decision node is set, it behaves exactly like a chance node that has been set as an evidence variable.".*

**Question 10**
Which effect is described when the exact wording (e.g., "90% survival rate" versus "10% death rate") of a decision problem significantly impacts an agent's choices?
**D) Framing effect**
*Supporting Quote: "Yet another problem is that the exact wording of a decision problem can have a big impact on the agent’s choices; this is called the **framing effect**.".*

**Question 11**
What is the fundamental difference between a **normative theory** and a **descriptive theory** of decision-making?
**B) Normative theory describes how a rational agent should act, while descriptive theory describes how actual agents really do act.**
*Supporting Quote: "Decision theory is a **normative theory**: it describes how a rational agent should act. A **descriptive theory**, on the other hand, describes how actual agents—for example, humans—really do act.".*

**Question 12**
What does the **Value of Information (VPI)** specifically measure?
**B) The maximum amount an agent should be willing to pay for information, defined as the expected gain in utility resulting from having the information before acting.**
*Supporting Quote: "The value of a given piece of information is defined to be the difference in expected value between best actions before and after information is obtained."; "The value of information is defined as the expected improvement in utility compared with making a decision without the information...".*

**Question 13**
In the context of decision networks, what is the graphical symbol used to represent a **utility node**?
**C) Diamond**
*Supporting Quote: "Utility nodes (diamonds) represent the agent’s utility function.".*

**Question 14**
Which important property of sensing actions is highlighted by the fact that the total VPI gained from a sequence of observations is independent of the order in which they are performed?
**B) Order independence**
*Supporting Quote: "Order independence distinguishes sensing actions from ordinary actions and simplifies the problem of calculating the value of a sequence of sensing actions.".*

**Question 15**
What primary incentive causes a robot operating under uncertainty about a human's preferences to choose to **defer** to the human (e.g., allow itself to be switched off)?
**C) The robot's uncertainty creates a positive expected gain in utility from receiving information about the human's true, underlying preferences.**
*Supporting Quote: "The upshot is that Robbie has a positive incentive to defer to Harriet—that is, to allow himself to be switched off. This incentive comes directly from Robbie’s uncertainty about Harriet’s preferences."; "We showed by a simple argument that uncertainty about preferences ensures that the machine defers to the human, to the point of allowing itself to be switched off.".*
