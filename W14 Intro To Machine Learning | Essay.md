**Chapter 19: Learning from Examples**

1.  Explain the core concepts of the **bias–variance tradeoff** in supervised learning. How does the choice of hypothesis space capacity influence whether a model is likely to suffer from **underfitting** or **overfitting**, and what guiding principle (**Ockham’s razor**) is often invoked to navigate this critical decision?
2.  Critically evaluate the inherent conflict between **minimizing empirical loss** on a training set and ensuring optimal **generalization loss** on unseen data. Discuss how **regularization** (L1 or L2) acts as a mechanism to temper this conflict, and explain the specific advantage of **L1 regularization** in promoting **sparse models**.
3.  Analyze the limitations imposed by the **curse of dimensionality** on algorithms like **k-nearest-neighbors**. How do models like **Support Vector Machines (SVMs)** utilize the **kernel trick** to efficiently generalize data that is not linearly separable without suffering from the massive memory and computational costs associated with high-dimensional explicit feature spaces?
4.  Explain how **Ensemble Learning** methods such as **Bagging** and **Boosting** fundamentally differ in their primary objective (reducing variance versus reducing bias). Discuss the implications of **Adaboost’s** process of sequentially adjusting example weights, including the surprising observation that performance can continue to improve even after **training set error reaches zero**.
5.  The **PAC learning** framework provides theoretical guarantees regarding generalization. Explain the key components of the PAC inequality (N, $\epsilon$, $\delta$, $|H|$). What is the philosophical and practical implication of the finding that the sample complexity for Boolean functions grows **exponentially** with the number of attributes?
