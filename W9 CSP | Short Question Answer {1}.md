### Part 2: Model Answers
1.  **Core Concept:** CSPs use a **factored representation** of states (variable/value pairs), allowing solvers to leverage constraints to quickly **prune large swathes of the search space** where combinations violate constraints. Atomic searchers, treating states as indivisible "black boxes," lack this structural insight for early pruning.
2.  **Core Concept:** Constraint propagation enforces **local consistency** (e.g., arc consistency) by iteratively inspecting variable domains to remove values inconsistent with neighboring variable domains. This process acts as **inference**, potentially solving the problem entirely or dramatically reducing domains before search begins, thereby avoiding redundant assignments.
3.  **Core Concept:** Commutativity means the order in which assignments are made does not affect the final solution. This allows backtracking search to be specialized so that only one variable is assigned a value at each depth level, which significantly **reduces the search space** from $n! \cdot d^n$ possible paths to just $d^n$ complete assignments.
4.  **Core Concept:** The least-constraining-value heuristic guides the search by prioritizing values that **eliminate the fewest options for neighboring unassigned variables** in the constraint graph. The strategic goal is to retain **maximum flexibility** for later assignments, minimizing the probability of reaching a dead end deep within the search.
5.  **Core Concept:** The min-conflicts algorithm solves large instances of the N-queens problem in a number of steps that is roughly independent of problem size. This indicates that solutions are **densely distributed** throughout the state space, meaning that a solution exists very close to almost any random starting assignment.
6.  **Core Concept:** Tree structures simplify constraint checking because any two variables are connected by only one path, meaning constraints are localized. The **TREE-CSP-SOLVER** algorithm exploits this by achieving directed arc consistency and then making assignments without any need for backtracking, resulting in linear time complexity, $O(nd^2)$.
7.  **Core Concept:** Special-purpose algorithms for global constraints can detect inconsistencies involving many variables simultaneously that binary constraint checks might miss. For instance, an *Alldiff* check can immediately signal failure if $m$ variables are restricted to domains containing fewer than $m$ distinct values, a complex failure pattern for simple arc consistency.
8.  **Core Concept:** Cutset conditioning involves an **exponential time cost $O(d^c)$** associated with trying every possible assignment to the $c$ variables in the cycle cutset $S$. This cost is traded against the benefit of reducing the remaining problem to a tree structure, which can then be solved efficiently in **linear time** $O((n-c)d^2)$.
