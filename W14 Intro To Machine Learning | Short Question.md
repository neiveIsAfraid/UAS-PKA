## Part 1: The Questions

1.  What is the implication of the **stationarity assumption** on the relationship between an agent's historical observations and its predictions for future examples?
2.  How does the principle of **Ockham's razor** relate to the **biasâ€“variance tradeoff** when selecting a hypothesis?
3.  Why is the **Occur Check** necessary in the unification algorithm, and what practical consequence results from omitting it in some systems?
4.  Explain how the decision to use **L1 regularization** rather than L2 regularization impacts the interpretability and robustness of a multivariable linear regression model.
5.  What is the practical risk of **Likelihood Weighting** when evidence variables are "downstream" from sampled variables in a Bayesian network, and what characteristic of the sampling distribution causes this?
6.  How does the **Expected Value of Information (VPI)** formally measure the expected benefit of performing an **information-gathering action** prior to taking a physical action?
7.  In decision theory, why is a utility function typically not proportional to monetary value, particularly for significant amounts of wealth?
8.  Why is **forward checking** in CSP solving preferred over simple chronological backtracking in terms of avoiding wasteful search effort?
9.  Why does the **Minimax algorithm** for game search perform a depth-first exploration of the entire game tree, leading to exponential time complexity in depth $m$ and branching factor $b$?
10. How do **Dynamic Bayesian Networks (DBNs)**, through their factored representation, overcome the state-space scaling issues inherent in Hidden Markov Models (HMMs) for complex sequential systems?

---
[This is the answer](https://github.com/neiveIsAfraid/UAS-PKA/blob/main/W14%20Learning%20From%20Examples%20%7C%20Short%20Answer.md)
