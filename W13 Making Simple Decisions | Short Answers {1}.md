## Part 1: The Questions

1.  Why must a rational agent adhere to the **Maximization of Expected Utility (MEU)** principle, rather than relying solely on logical goal attainment, when operating in uncertain environments?
2.  What is the fundamental implication of satisfying the axioms of utility theory (like transitivity and continuity) for an agent's preferences?
3.  How does a **Decision Network** or **Influence Diagram** integrate probabilistic reasoning with utility theory to solve a decision problem?
4.  Explain the utility of **stochastic dominance** in multiattribute decision-making, particularly in scenarios where the exact utility function is unknown.
5.  What is the critical implication of the theorem stating that the **Expected Value of Information (VPI)** is always non-negative?
6.  How does a rational agent decide whether to perform an information-gathering action, such as a medical test, when considering VPI alongside the cost of obtaining the information?
7.  What is the significance of the observation that humans are "**predictably irrational**," in contrast to the **normative theory** of expected utility?
8.  Why is decomposing a multiattribute utility function into an **additive value function** often highly desirable, even if the strict independence assumption is sometimes violated?
9.  In the context of unknown preferences (e.g., a robot interacting with a human), explain why a rational machine might choose to **defer to the human** or allow itself to be switched off.
10. The VPI of a sequence of observations is **order independent**. What computational advantage does this property offer to an agent designing an information-gathering strategy?

[This is the real answer](https://github.com/neiveIsAfraid/UAS-PKA/blob/main/W13%20Making%20Simple%20Decisions%20%7C%20Short%20Real%20Answer%7B1%7D.md)
