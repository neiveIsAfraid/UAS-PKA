**Chapter 13: Probabilistic Reasoning**

1.  Critically analyze the trade-offs inherent in building concise Bayesian network representations by adhering to a **causal ordering** (causes precede effects). Explain how specifying parameters (Conditional Probability Tables, or CPTs) based on causal influence not only promotes network **compactness** but also simplifies the judgment tasks required of domain experts, and discuss the implication of choosing a poor (diagnostic) ordering instead.
2.  The task of general probabilistic inference in Bayesian networks is characterized as being **\#P-hard**. Explain what this complexity classification implies for the feasibility of using **Exact Inference** algorithms, such as **Variable Elimination**, in large, realistic networks. Furthermore, discuss how the algorithm's complexity relates directly to the size of the intermediate factors it constructs, and how this size is constrained by the network's topology.
3.  Compare the mechanisms of **Rejection Sampling** and **Likelihood Weighting** in performing approximate inference, particularly focusing on their effectiveness when the probability of the evidence $P(e)$ is vanishingly small. Explain why Likelihood Weighting often significantly outperforms Rejection Sampling in complex scenarios, and detail the structural mechanism (Likelihood Weighting's fixing of evidence variables) that enables this efficiency.
4.  Analyze the role and impact of **canonical distributions**, such as **Noisy-OR**, in managing the parameter complexity of Bayesian networks. Discuss how these models achieve an exponential reduction in the required number of parameters (from $O(2^k)$ to $O(k)$), and critically evaluate the effect of the independence assumptions embedded within these models on the overall representational accuracy of the system.
5.  Explain the conceptual and formal distinction between a **passive observation** (conditioning on evidence) and an **external intervention** (using the **do-operator**) in a **Causal Network**. Discuss how the network's semantics formally model an intervention by creating a "mutilated model" and explain why this capability is essential for answering questions about the effects of policy or action, which traditional conditional probability cannot address.

**Chapter 14: Probabilistic Reasoning Over Time**

6.  Analyze the collective importance of the **Markov property** and **time-homogeneity** in achieving computational tractability for temporal probabilistic reasoning. How do these assumptions enable the core inference tasks (Filtering, Prediction, and Smoothing) to be solved efficiently using **recursive algorithms** whose complexity scales linearly with the length of the time sequence?
7.  Critically examine the limitations of using marginal probability distributions obtained via **Smoothing** ($P(X_k | e_{1:t})$) to determine the overall **most likely sequence of states** $x_{1:t}$. Explain why the resulting sequence (composed of the individually most likely states) is generally not the globally optimal sequence, necessitating the dedicated recursive approach of the **Viterbi Algorithm**.
8.  Contrast the design philosophies of **Hidden Markov Models (HMMs)** and **Dynamic Bayesian Networks (DBNs)** concerning the representation of complex state spaces. Discuss why HMMs face intractability due to exponential scaling when modeling systems with many internal variables, and synthesize how DBNs leverage a **factored representation** to achieve linear scaling in the number of state variables.
9.  Explain the fundamental problem **Likelihood Weighting** faces when applied to **Dynamic Bayesian Networks (DBNs)** due to the topology of temporal models (where early states are upstream from later evidence). Detail how **Particle Filtering** (a Sequential Monte Carlo method) successfully addresses this limitation by using recursive **resampling** to maintain a set of samples focused on high-probability regions of the continuous belief state.
10. Compare the structural constraints and modeling capabilities of **Hidden Markov Models (HMMs)** and **Kalman Filters**. Analyze why the assumption of a **Linear Dynamical System** (linear transitions and Gaussian distributions) in Kalman Filters is essential for maintaining a tractable, exact representation of the belief state (mean $\mu$ and covariance $\Sigma$) in continuous domains, contrasting this with the discrete, atomic state representation of HMMs.
