1. Analyze the relationship between **constraint propagation** (inference) and **search** (backtracking or local search) in a CSP solver. How does the philosophy of using inference to enforce local consistency (e.g., via AC-3) fundamentally change the performance profile of the subsequent search phase, and what are the trade-offs regarding time, memory consumption, and guaranteed completeness inherent in optimizing the balance between propagation depth and search breadth?

2. The tractability of a CSP is often determined by the **structure of its constraint graph**. Critically evaluate two distinct methods for exploiting problem structure—**cutset conditioning** and **tree decomposition**—in transforming a complex CSP into a form solvable with linear complexity. Discuss the comparative computational overhead (e.g., finding the cutset vs. constructing the decomposition) and the structural property (cutset size vs. tree width) that determines the ultimate efficiency of each approach.

3. Backtracking search benefits significantly from the **commutativity property** of CSPs, which limits variable choices at each depth level. Analyze how the combination of domain-independent search heuristics (such as MRV or LCV) and propagation mechanisms (such as forward checking or conflict-directed backjumping) strategically utilizes the information derived from constraints to realize the maximum theoretical efficiency gains possible within the resulting reduced search space.

4. Compare and contrast the fundamental algorithmic approach and empirical success factors of **backtracking search** and **local search** methods for CSPs. Drawing specifically on the examples of applying the **min-conflicts heuristic** to the $N$-queens problem, explain why certain problems, characterized by a dense distribution of solutions in the state space, are disproportionately better suited to local search over complete assignments than to systematic backtracking over partial assignments.

5. Discuss the computational justification for developing and utilizing specialized inference algorithms for **global constraints** (such as *Alldiff* or resource constraints) rather than strictly adhering to the simplification strategy of converting all constraints into an equivalent **binary CSP**. What are the specific inconsistencies detectable by these global inference algorithms that might be missed or detected less efficiently by enforcing only basic **arc consistency** (AC-3) on the binary constraint equivalent?
