## Quiz Section

### Chapter 19: Learning from Examples

**Question 1**\
What is the process called when a computer observes some data, builds a model, and uses the model as both a hypothesis about the world and a piece of software that can solve problems?\
A) Artificial Intelligence\
B) Computational Learning Theory\
C) Machine Learning\
D) Knowledge Engineering

**Question 2**\
What type of learning involves the agent observing labeled input-output pairs and learning a function that maps from input to output?\
A) Reinforcement learning\
B) Unsupervised learning\
C) Supervised learning\
D) Transfer learning

**Question 3**\
The function $h$ discovered in supervised learning is called a hypothesis and is drawn from $H$, which is defined as the set of possible functions or theories. What is $H$ called?\
A) Training set\
B) Feature set\
C) Loss function\
D) Hypothesis space

**Question 4**\
In supervised learning, what is defined as the true measure of a hypothesis's success?\
A) How well it minimizes empirical loss on the training set.\
B) How well it generalizes to inputs it has not yet seen (test set).\
C) How quickly it converges during optimization.\
D) How simple and concise the hypothesis is.

**Question 5**\
What is the metric used by the decision tree learning algorithm to choose the "most important attribute" for splitting at a node, corresponding to the expected reduction in entropy?\
A) Squared-error loss\
B) Information gain\
C) Maximum likelihood\
D) Myopic utility

**Question 6**\
When a model fits the training data too closely, capturing random noise or random variations rather than generalizable patterns, this phenomenon is known as:\
A) Underfitting\
B) Regularization\
C) Overfitting\
D) PAC learning

**Question 7**\
The assumption that examples are drawn independently from the same underlying probability distribution is known by which abbreviation?\
A) ML (Maximum Likelihood)\
B) VPI (Value of Information)\
C) MEU (Maximizing Expected Utility)\
D) I.i.d. (Independent and identically distributed)

**Question 8**\
What technique involves adding a penalty term based on the complexity of the hypothesis to the loss function to minimize a weighted sum of empirical loss and complexity, thereby combating overfitting?\
A) K-fold cross-validation\
B) Regularization\
C) Ensemble learning\
D) Nonparametric modeling

**Question 9**\
In the context of linear functions used for regression (fitting a straight line), what is the most common loss function minimized to find the optimal weights $w$ in the model?\
A) Absolute-value loss ($L1$)\
B) Zero/one loss ($L0/1$)\
C) Squared-error loss ($L2$)\
D) Framing effect loss

**Question 10**\
In linear classification, a straight line (or a surface in higher dimensions) that separates the two classes is known as a:\
A) Support vector\
B) Stochastic boundary\
C) Decision boundary (or Linear separator)\
D) Gaussian kernel

**Question 11**\
What category of model retains all training data, and whose structure and complexity scale with the size of the training set (e.g., k-nearest neighbors)?\
A) Linear model\
B) Parametric model\
C) Nonparametric model\
D) Logical model

**Question 12**\
In Support Vector Machines (SVMs), the objective is to find the separator that is farthest away from the closest examples. This distance to the nearest examples is called the:\
A) Support distance\
B) Margin\
C) Boundary depth\
D) Kernel width

**Question 13**\
Ensemble learning methods, such as bagging and boosting, primarily aim to improve prediction performance by reducing what aspect of the base models?\
A) The cost of computation.\
B) The number of features required.\
C) Bias or variance.\
D) The time needed for data collection.

**Question 14**\
The Boosting ensemble method sequentially generates hypotheses, deliberately giving more weight to which type of examples in subsequent training rounds?\
A) Examples with the lowest complexity.\
B) Examples that were correctly classified in the previous round.\
C) Examples that were previously misclassified.\
D) Examples where the expected utility was highest.

**Question 15**\
In the context of online learning and aggregating the predictions of experts, what is the term used to measure the number of additional mistakes made compared to the expert who had the best prediction record in hindsight?\
A) Total cost\
B) Regret\
C) Expected loss\
D) Complexity penalty

***

[This is the solution](https://github.com/neiveIsAfraid/UAS-PKA/blob/main/W14%20Intro%20To%20Machine%20Learning%20%7C%20MCQ%20Ansers.md)
