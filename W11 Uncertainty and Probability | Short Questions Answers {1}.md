### Part 2: Model Answers

1.  **Core Concept:** Maximizing expected utility (MEU) translates the "global" definition of rationality (highest performance) into a "local" constraint on agent design. This allows the agent to make rational decisions using a simple program that does not depend on the specific utility function being maximized.
2.  **Core Concept:** Probability theory solves the logical qualification problem by **summarizing the uncertainty** that arises from laziness and ignorance. Instead of having to list every arbitrarily unlikely exception that could cause a rule to fail, probability assigns a numerical degree of belief to the outcome.
3.  **Core Concept:** Probability statements are made with respect to a **knowledge state**, not the real world. The probability reflects the agent's current set of evidence; as the agent gathers more evidence, the probability statement (degree of belief) is updated, even though the underlying state of the patient remains fixed.
4.  **Core Concept:** The full joint distribution requires $O(2^n)$ memory and time for $n$ Boolean variables, making it impractical for large domains ($n \approx 100$). **Absolute independence** allows the joint distribution to be **factored** into smaller joint distributions, greatly reducing complexity and the number of probabilities that must be estimated.
5.  **Core Concept:** Bayes' Rule allows the agent to calculate difficult-to-estimate **diagnostic probabilities** ($\text{P}(\text{cause} | \text{effect})$) from often readily available or known **causal probabilities** ($\text{P}(\text{effect} | \text{cause})$). This is crucial because experts often prefer to give causal probability judgments.
6.  **Core Concept:** The Naive Bayes model assumes that all **effect variables are conditionally independent given the single cause variable**. While this structure simplifies representation, the assumption is frequently violated, leading to model predictions that are often **overconfident**, with probabilities very close to 0 or 1.
7.  **Core Concept:** The probabilistic agent gains the ability to calculate the **likelihoods** for unobserved aspects of the world (like the locations of pits or the wumpus). This enables the agent to find the **most likely safe square**, thus making a rational decision that improves performance over a purely logical agent that might otherwise have to choose randomly.
8.  **Core Concept:** Diagnostic probabilities ($\text{P}(\text{cause} | \text{effect})$) are hard to estimate directly because they require calculating the **prior probability of the evidence** ($\text{P}(\text{effect})$), which often involves summing over the full joint distribution over all possible causes and hidden variables, a process that does not scale well.
9.  **Core Concept:** An agent whose degrees of belief do not conform to the axioms of probability is susceptible to a **Dutch book**, a set of bets that guarantees a loss for the agent regardless of the outcomes of the events.
10. **Core Concept:** The unobserved variables $Y$ must be **summed out (marginalized over)** in the joint distribution $\text{P}(X, e, Y)$ to find the total probability mass corresponding to the query $X$ and the observed evidence $e$. The factor $\alpha$ then **normalizes** this result to ensure the final conditional probabilities sum to one.
